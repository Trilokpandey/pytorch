{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Rb1tj6S90RcF",
        "outputId": "6efda200-eb05-4fb8-852c-8d87cf609e8d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          question      answer\n",
              "0                   What is the capital of France?       Paris\n",
              "1                  What is the capital of Germany?      Berlin\n",
              "2               Who wrote 'To Kill a Mockingbird'?  Harper-Lee\n",
              "3  What is the largest planet in our solar system?     Jupiter\n",
              "4   What is the boiling point of water in Celsius?         100"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8a1e8c39-34f1-4037-839d-acec70f9ca71\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the capital of France?</td>\n",
              "      <td>Paris</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the capital of Germany?</td>\n",
              "      <td>Berlin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Who wrote 'To Kill a Mockingbird'?</td>\n",
              "      <td>Harper-Lee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the largest planet in our solar system?</td>\n",
              "      <td>Jupiter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the boiling point of water in Celsius?</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a1e8c39-34f1-4037-839d-acec70f9ca71')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8a1e8c39-34f1-4037-839d-acec70f9ca71 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8a1e8c39-34f1-4037-839d-acec70f9ca71');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-09c45c7c-06bc-4588-846a-b5e24b527928\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-09c45c7c-06bc-4588-846a-b5e24b527928')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-09c45c7c-06bc-4588-846a-b5e24b527928 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 90,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 90,\n        \"samples\": [\n          \"What is the currency of China?\",\n          \"What is the capital of Australia?\",\n          \"Who discovered electricity?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 85,\n        \"samples\": [\n          \"ChristopherColumbus\",\n          \"Paris\",\n          \"Christmas\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/100_Unique_QA_Dataset.csv\")\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize\n",
        "def tokenize(text):\n",
        "  text = text.lower()\n",
        "  text = text.replace(\"?\",\"\")\n",
        "  text = text.replace(\"'\",\"\")\n",
        "  return text.split()"
      ],
      "metadata": {
        "id": "WGZ1zyeY3PBW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize(\"What is the boiling point of water in Celsius?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVlvAodN4jml",
        "outputId": "6e3280cf-aa8e-4788-9f81-a442c2604480"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what', 'is', 'the', 'boiling', 'point', 'of', 'water', 'in', 'celsius']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create vocabulary of unique words\n",
        "\n",
        "vocab = {'<UNK>':0}\n",
        "\n",
        "def build_vocab(row):\n",
        "  tokenized_question = tokenize(row['question'])\n",
        "  tokenized_answer = tokenize(row['answer'])\n",
        "  merged_tokens = tokenized_question + tokenized_answer\n",
        "\n",
        "  for token in merged_tokens:\n",
        "\n",
        "    if token not in vocab:\n",
        "      vocab[token] = len(vocab)\n"
      ],
      "metadata": {
        "id": "7yju0dD_3O9_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.apply(build_vocab,axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "BnpQ-vbm5fLU",
        "outputId": "724dd1b4-f1ce-4fcd-f674-f3e072cb7655"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     None\n",
              "1     None\n",
              "2     None\n",
              "3     None\n",
              "4     None\n",
              "      ... \n",
              "85    None\n",
              "86    None\n",
              "87    None\n",
              "88    None\n",
              "89    None\n",
              "Length: 90, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>90 rows Ã— 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qkd1QX417vl2",
        "outputId": "8e544e32-2448-4b5a-c94a-e9e0c0937e1a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<UNK>': 0,\n",
              " 'what': 1,\n",
              " 'is': 2,\n",
              " 'the': 3,\n",
              " 'capital': 4,\n",
              " 'of': 5,\n",
              " 'france': 6,\n",
              " 'paris': 7,\n",
              " 'germany': 8,\n",
              " 'berlin': 9,\n",
              " 'who': 10,\n",
              " 'wrote': 11,\n",
              " 'to': 12,\n",
              " 'kill': 13,\n",
              " 'a': 14,\n",
              " 'mockingbird': 15,\n",
              " 'harper-lee': 16,\n",
              " 'largest': 17,\n",
              " 'planet': 18,\n",
              " 'in': 19,\n",
              " 'our': 20,\n",
              " 'solar': 21,\n",
              " 'system': 22,\n",
              " 'jupiter': 23,\n",
              " 'boiling': 24,\n",
              " 'point': 25,\n",
              " 'water': 26,\n",
              " 'celsius': 27,\n",
              " '100': 28,\n",
              " 'painted': 29,\n",
              " 'mona': 30,\n",
              " 'lisa': 31,\n",
              " 'leonardo-da-vinci': 32,\n",
              " 'square': 33,\n",
              " 'root': 34,\n",
              " '64': 35,\n",
              " '8': 36,\n",
              " 'chemical': 37,\n",
              " 'symbol': 38,\n",
              " 'for': 39,\n",
              " 'gold': 40,\n",
              " 'au': 41,\n",
              " 'which': 42,\n",
              " 'year': 43,\n",
              " 'did': 44,\n",
              " 'world': 45,\n",
              " 'war': 46,\n",
              " 'ii': 47,\n",
              " 'end': 48,\n",
              " '1945': 49,\n",
              " 'longest': 50,\n",
              " 'river': 51,\n",
              " 'nile': 52,\n",
              " 'japan': 53,\n",
              " 'tokyo': 54,\n",
              " 'developed': 55,\n",
              " 'theory': 56,\n",
              " 'relativity': 57,\n",
              " 'albert-einstein': 58,\n",
              " 'freezing': 59,\n",
              " 'fahrenheit': 60,\n",
              " '32': 61,\n",
              " 'known': 62,\n",
              " 'as': 63,\n",
              " 'red': 64,\n",
              " 'mars': 65,\n",
              " 'author': 66,\n",
              " '1984': 67,\n",
              " 'george-orwell': 68,\n",
              " 'currency': 69,\n",
              " 'united': 70,\n",
              " 'kingdom': 71,\n",
              " 'pound': 72,\n",
              " 'india': 73,\n",
              " 'delhi': 74,\n",
              " 'discovered': 75,\n",
              " 'gravity': 76,\n",
              " 'newton': 77,\n",
              " 'how': 78,\n",
              " 'many': 79,\n",
              " 'continents': 80,\n",
              " 'are': 81,\n",
              " 'there': 82,\n",
              " 'on': 83,\n",
              " 'earth': 84,\n",
              " '7': 85,\n",
              " 'gas': 86,\n",
              " 'do': 87,\n",
              " 'plants': 88,\n",
              " 'use': 89,\n",
              " 'photosynthesis': 90,\n",
              " 'co2': 91,\n",
              " 'smallest': 92,\n",
              " 'prime': 93,\n",
              " 'number': 94,\n",
              " '2': 95,\n",
              " 'invented': 96,\n",
              " 'telephone': 97,\n",
              " 'alexander-graham-bell': 98,\n",
              " 'australia': 99,\n",
              " 'canberra': 100,\n",
              " 'ocean': 101,\n",
              " 'pacific-ocean': 102,\n",
              " 'speed': 103,\n",
              " 'light': 104,\n",
              " 'vacuum': 105,\n",
              " '299,792,458m/s': 106,\n",
              " 'language': 107,\n",
              " 'spoken': 108,\n",
              " 'brazil': 109,\n",
              " 'portuguese': 110,\n",
              " 'penicillin': 111,\n",
              " 'alexander-fleming': 112,\n",
              " 'canada': 113,\n",
              " 'ottawa': 114,\n",
              " 'mammal': 115,\n",
              " 'whale': 116,\n",
              " 'element': 117,\n",
              " 'has': 118,\n",
              " 'atomic': 119,\n",
              " '1': 120,\n",
              " 'hydrogen': 121,\n",
              " 'tallest': 122,\n",
              " 'mountain': 123,\n",
              " 'everest': 124,\n",
              " 'city': 125,\n",
              " 'big': 126,\n",
              " 'apple': 127,\n",
              " 'newyork': 128,\n",
              " 'planets': 129,\n",
              " 'starry': 130,\n",
              " 'night': 131,\n",
              " 'vangogh': 132,\n",
              " 'formula': 133,\n",
              " 'h2o': 134,\n",
              " 'italy': 135,\n",
              " 'rome': 136,\n",
              " 'country': 137,\n",
              " 'famous': 138,\n",
              " 'sushi': 139,\n",
              " 'was': 140,\n",
              " 'first': 141,\n",
              " 'person': 142,\n",
              " 'step': 143,\n",
              " 'moon': 144,\n",
              " 'armstrong': 145,\n",
              " 'main': 146,\n",
              " 'ingredient': 147,\n",
              " 'guacamole': 148,\n",
              " 'avocado': 149,\n",
              " 'sides': 150,\n",
              " 'does': 151,\n",
              " 'hexagon': 152,\n",
              " 'have': 153,\n",
              " '6': 154,\n",
              " 'china': 155,\n",
              " 'yuan': 156,\n",
              " 'pride': 157,\n",
              " 'and': 158,\n",
              " 'prejudice': 159,\n",
              " 'jane-austen': 160,\n",
              " 'iron': 161,\n",
              " 'fe': 162,\n",
              " 'hardest': 163,\n",
              " 'natural': 164,\n",
              " 'substance': 165,\n",
              " 'diamond': 166,\n",
              " 'continent': 167,\n",
              " 'by': 168,\n",
              " 'area': 169,\n",
              " 'asia': 170,\n",
              " 'president': 171,\n",
              " 'states': 172,\n",
              " 'george-washington': 173,\n",
              " 'bird': 174,\n",
              " 'its': 175,\n",
              " 'ability': 176,\n",
              " 'mimic': 177,\n",
              " 'sounds': 178,\n",
              " 'parrot': 179,\n",
              " 'longest-running': 180,\n",
              " 'animated': 181,\n",
              " 'tv': 182,\n",
              " 'show': 183,\n",
              " 'simpsons': 184,\n",
              " 'vaticancity': 185,\n",
              " 'most': 186,\n",
              " 'moons': 187,\n",
              " 'saturn': 188,\n",
              " 'romeo': 189,\n",
              " 'juliet': 190,\n",
              " 'shakespeare': 191,\n",
              " 'earths': 192,\n",
              " 'atmosphere': 193,\n",
              " 'nitrogen': 194,\n",
              " 'bones': 195,\n",
              " 'adult': 196,\n",
              " 'human': 197,\n",
              " 'body': 198,\n",
              " '206': 199,\n",
              " 'metal': 200,\n",
              " 'liquid': 201,\n",
              " 'at': 202,\n",
              " 'room': 203,\n",
              " 'temperature': 204,\n",
              " 'mercury': 205,\n",
              " 'russia': 206,\n",
              " 'moscow': 207,\n",
              " 'electricity': 208,\n",
              " 'benjamin-franklin': 209,\n",
              " 'second-largest': 210,\n",
              " 'land': 211,\n",
              " 'color': 212,\n",
              " 'ripe': 213,\n",
              " 'banana': 214,\n",
              " 'yellow': 215,\n",
              " 'month': 216,\n",
              " '28': 217,\n",
              " 'days': 218,\n",
              " 'common': 219,\n",
              " 'february': 220,\n",
              " 'study': 221,\n",
              " 'living': 222,\n",
              " 'organisms': 223,\n",
              " 'called': 224,\n",
              " 'biology': 225,\n",
              " 'home': 226,\n",
              " 'great': 227,\n",
              " 'wall': 228,\n",
              " 'bees': 229,\n",
              " 'collect': 230,\n",
              " 'from': 231,\n",
              " 'flowers': 232,\n",
              " 'nectar': 233,\n",
              " 'opposite': 234,\n",
              " 'day': 235,\n",
              " 'south': 236,\n",
              " 'korea': 237,\n",
              " 'seoul': 238,\n",
              " 'bulb': 239,\n",
              " 'edison': 240,\n",
              " 'humans': 241,\n",
              " 'breathe': 242,\n",
              " 'survival': 243,\n",
              " 'oxygen': 244,\n",
              " '144': 245,\n",
              " '12': 246,\n",
              " 'pyramids': 247,\n",
              " 'giza': 248,\n",
              " 'egypt': 249,\n",
              " 'sea': 250,\n",
              " 'creature': 251,\n",
              " 'eight': 252,\n",
              " 'arms': 253,\n",
              " 'octopus': 254,\n",
              " 'holiday': 255,\n",
              " 'celebrated': 256,\n",
              " 'december': 257,\n",
              " '25': 258,\n",
              " 'christmas': 259,\n",
              " 'yen': 260,\n",
              " 'legs': 261,\n",
              " 'spider': 262,\n",
              " 'sport': 263,\n",
              " 'uses': 264,\n",
              " 'net,': 265,\n",
              " 'ball,': 266,\n",
              " 'hoop': 267,\n",
              " 'basketball': 268,\n",
              " 'kangaroos': 269,\n",
              " 'female': 270,\n",
              " 'minister': 271,\n",
              " 'uk': 272,\n",
              " 'margaretthatcher': 273,\n",
              " 'fastest': 274,\n",
              " 'animal': 275,\n",
              " 'cheetah': 276,\n",
              " 'periodic': 277,\n",
              " 'table': 278,\n",
              " 'spain': 279,\n",
              " 'madrid': 280,\n",
              " 'closest': 281,\n",
              " 'sun': 282,\n",
              " 'father': 283,\n",
              " 'computers': 284,\n",
              " 'charlesbabbage': 285,\n",
              " 'mexico': 286,\n",
              " 'mexicocity': 287,\n",
              " 'colors': 288,\n",
              " 'rainbow': 289,\n",
              " 'musical': 290,\n",
              " 'instrument': 291,\n",
              " 'black': 292,\n",
              " 'white': 293,\n",
              " 'keys': 294,\n",
              " 'piano': 295,\n",
              " 'americas': 296,\n",
              " '1492': 297,\n",
              " 'christophercolumbus': 298,\n",
              " 'disney': 299,\n",
              " 'character': 300,\n",
              " 'long': 301,\n",
              " 'nose': 302,\n",
              " 'grows': 303,\n",
              " 'it': 304,\n",
              " 'when': 305,\n",
              " 'lying': 306,\n",
              " 'pinocchio': 307,\n",
              " 'directed': 308,\n",
              " 'movie': 309,\n",
              " 'titanic': 310,\n",
              " 'jamescameron': 311,\n",
              " 'superhero': 312,\n",
              " 'also': 313,\n",
              " 'dark': 314,\n",
              " 'knight': 315,\n",
              " 'batman': 316,\n",
              " 'brasilia': 317,\n",
              " 'fruit': 318,\n",
              " 'king': 319,\n",
              " 'fruits': 320,\n",
              " 'mango': 321,\n",
              " 'eiffel': 322,\n",
              " 'tower': 323}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upebwHTp7y8y",
        "outputId": "5e2aad90-516d-4f24-f7e3-4f0fc3a64224"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "324"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert words into numerical indices\n",
        "\n",
        "def text_to_indices(text,vocab):\n",
        "\n",
        "  indexed_text = []\n",
        "\n",
        "  for token in tokenize(text):\n",
        "\n",
        "    if token in vocab:\n",
        "      indexed_text.append(vocab[token])\n",
        "    else:\n",
        "      indexed_text.append(vocab['<UNK>'])\n",
        "\n",
        "  return indexed_text\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "K4cuURxS3O6y"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_to_indices(\"what is my name?\",vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YN-T4tx9FMz",
        "outputId": "48db1a18-ab4b-49f0-b7de-a4d3bccdf551"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the libary\n",
        "import torch\n",
        "from torch.utils.data import Dataset,DataLoader\n"
      ],
      "metadata": {
        "id": "0Sujazr49I9I"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QADataset(Dataset):\n",
        "\n",
        "  def __init__(self,df,vocab):\n",
        "    self.df = df\n",
        "    self.vocab = vocab\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.df.shape[0]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    numerical_question = text_to_indices(self.df.iloc[index]['question'],self.vocab)\n",
        "    numerical_answer = text_to_indices(self.df.iloc[index]['answer'],self.vocab)\n",
        "\n",
        "    return torch.tensor(numerical_question),torch.tensor(numerical_answer)\n"
      ],
      "metadata": {
        "id": "QgxA3t-X9r6R"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = QADataset(df,vocab)"
      ],
      "metadata": {
        "id": "J6hAymDB9ryk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv6d7JRJ9rvJ",
        "outputId": "89b1f830-b3cf-4447-87dc-b2ee34d03a93"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1, 2, 3, 4, 5, 6]), tensor([7]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset,batch_size=1, shuffle=True)"
      ],
      "metadata": {
        "id": "g9AVgcCU9rrj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for question,answer in dataloader:\n",
        "  print(question,answer)\n",
        "print(question.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vS2NuYPMA7Gv",
        "outputId": "4c3f9f19-e8e8-43c5-c8d3-084dcd6c0e52"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 42, 125,   2,  62,  63,   3, 126, 127]]) tensor([[128]])\n",
            "tensor([[ 10, 140,   3, 141, 142,  12, 143,  83,   3, 144]]) tensor([[145]])\n",
            "tensor([[ 42, 167,   2,   3,  17, 168, 169]]) tensor([[170]])\n",
            "tensor([[  1,   2,   3,  37, 133,   5,  26]]) tensor([[134]])\n",
            "tensor([[ 1,  2,  3, 37, 38, 39, 40]]) tensor([[41]])\n",
            "tensor([[ 42, 174,   2,  62,  39, 175, 176,  12, 177, 178]]) tensor([[179]])\n",
            "tensor([[ 42, 290, 291, 118, 292, 158, 293, 294]]) tensor([[295]])\n",
            "tensor([[  1,   2,   3, 103,   5, 104,  19, 105]]) tensor([[106]])\n",
            "tensor([[10, 29,  3, 30, 31]]) tensor([[32]])\n",
            "tensor([[ 1,  2,  3, 69,  5, 53]]) tensor([[260]])\n",
            "tensor([[ 42, 117, 118,   3, 119,  94, 120]]) tensor([[121]])\n",
            "tensor([[ 42, 312,   2, 313,  62,  63,   3, 314, 315]]) tensor([[316]])\n",
            "tensor([[ 10,  11, 157, 158, 159]]) tensor([[160]])\n",
            "tensor([[ 42, 250, 251, 118, 252, 253]]) tensor([[254]])\n",
            "tensor([[  1,   2,   3,   4,   5, 206]]) tensor([[207]])\n",
            "tensor([[ 42, 137,   2, 138,  39, 139]]) tensor([[53]])\n",
            "tensor([[  1,   2,   3,   4,   5, 113]]) tensor([[114]])\n",
            "tensor([[  1,   2,   3,  17, 115,  83,  84]]) tensor([[116]])\n",
            "tensor([[  1,   2,   3,   4,   5, 286]]) tensor([[287]])\n",
            "tensor([[ 42, 137,   2, 138,  39, 175, 269]]) tensor([[99]])\n",
            "tensor([[  1,   2,   3, 141, 117,  83,   3, 277, 278]]) tensor([[121]])\n",
            "tensor([[ 10,  29, 130, 131]]) tensor([[132]])\n",
            "tensor([[  1,   2,   3,  33,  34,   5, 245]]) tensor([[246]])\n",
            "tensor([[  1,   2,   3,  92, 137,  19,   3,  45]]) tensor([[185]])\n",
            "tensor([[  1,   2,   3,  69,   5, 155]]) tensor([[156]])\n",
            "tensor([[ 42, 255,   2, 256,  83, 257, 258]]) tensor([[259]])\n",
            "tensor([[ 42, 101,   2,   3,  17]]) tensor([[102]])\n",
            "tensor([[ 42, 200,   2,  14, 201, 202, 203, 204]]) tensor([[205]])\n",
            "tensor([[ 1,  2,  3, 50, 51, 19,  3, 45]]) tensor([[52]])\n",
            "tensor([[ 42, 318,   2,  62,  63,   3, 319,   5, 320]]) tensor([[321]])\n",
            "tensor([[ 1,  2,  3, 69,  5,  3, 70, 71]]) tensor([[72]])\n",
            "tensor([[ 78,  79, 261, 151,  14, 262, 153]]) tensor([[36]])\n",
            "tensor([[  1,   2,   3, 122, 123,  19,   3,  45]]) tensor([[124]])\n",
            "tensor([[ 1,  2,  3, 59, 25,  5, 26, 19, 60]]) tensor([[61]])\n",
            "tensor([[ 1,  2,  3, 92, 93, 94]]) tensor([[95]])\n",
            "tensor([[ 78,  79, 195,  81,  19,   3, 196, 197, 198]]) tensor([[199]])\n",
            "tensor([[ 78,  79, 129,  81,  19,   3,  21,  22]]) tensor([[36]])\n",
            "tensor([[  1,   2,   3, 146,  86,  19, 192, 193]]) tensor([[194]])\n",
            "tensor([[  1,   2,   3,  37,  38,  39, 161]]) tensor([[162]])\n",
            "tensor([[ 1,  2,  3,  4,  5, 73]]) tensor([[74]])\n",
            "tensor([[ 42, 137, 118,   3, 247,   5, 248]]) tensor([[249]])\n",
            "tensor([[ 10, 140,   3, 141, 270,  93, 271,   5,   3, 272]]) tensor([[273]])\n",
            "tensor([[ 10, 140,   3, 141, 171,   5,   3,  70, 172]]) tensor([[173]])\n",
            "tensor([[ 10,  75,   3, 296,  19, 297]]) tensor([[298]])\n",
            "tensor([[ 1,  2,  3,  4,  5, 99]]) tensor([[100]])\n",
            "tensor([[1, 2, 3, 4, 5, 6]]) tensor([[7]])\n",
            "tensor([[  1,   2,   3, 234,   5, 235]]) tensor([[131]])\n",
            "tensor([[ 1,  2,  3, 33, 34,  5, 35]]) tensor([[36]])\n",
            "tensor([[ 10,  96,   3, 104, 239]]) tensor([[240]])\n",
            "tensor([[ 10,  75, 111]]) tensor([[112]])\n",
            "tensor([[  1,   2,   3,   4,   5, 135]]) tensor([[136]])\n",
            "tensor([[10, 55,  3, 56,  5, 57]]) tensor([[58]])\n",
            "tensor([[ 1,  2,  3, 17, 18, 19, 20, 21, 22]]) tensor([[23]])\n",
            "tensor([[1, 2, 3, 4, 5, 8]]) tensor([[9]])\n",
            "tensor([[ 42,  86,  87, 241, 242,  19,  39, 243]]) tensor([[244]])\n",
            "tensor([[10, 75, 76]]) tensor([[77]])\n",
            "tensor([[42, 18,  2, 62, 63,  3, 64, 18]]) tensor([[65]])\n",
            "tensor([[42, 43, 44, 45, 46, 47, 48]]) tensor([[49]])\n",
            "tensor([[  1,   2,   3, 163, 164, 165,  83,  84]]) tensor([[166]])\n",
            "tensor([[ 10, 308,   3, 309, 310]]) tensor([[311]])\n",
            "tensor([[  1,   2,   3, 180, 181, 182, 183]]) tensor([[184]])\n",
            "tensor([[  1,  87, 229, 230, 231, 232]]) tensor([[233]])\n",
            "tensor([[ 1,  2,  3, 24, 25,  5, 26, 19, 27]]) tensor([[28]])\n",
            "tensor([[10,  2,  3, 66,  5, 67]]) tensor([[68]])\n",
            "tensor([[ 42, 263, 264,  14, 265, 266, 158, 267]]) tensor([[268]])\n",
            "tensor([[ 78,  79, 288,  81,  19,  14, 289]]) tensor([[85]])\n",
            "tensor([[ 42,  18,   2,   3, 281,  12,   3, 282]]) tensor([[205]])\n",
            "tensor([[ 42,  18, 118,   3, 186, 187]]) tensor([[188]])\n",
            "tensor([[ 42, 299, 300, 118,  14, 301, 302, 158, 303, 304, 305, 306]]) tensor([[307]])\n",
            "tensor([[10, 11, 12, 13, 14, 15]]) tensor([[16]])\n",
            "tensor([[42, 86, 87, 88, 89, 39, 90]]) tensor([[91]])\n",
            "tensor([[ 42, 216, 118, 217, 218,  19,  14, 219,  43]]) tensor([[220]])\n",
            "tensor([[ 10,   2,  62,  63,   3, 283,   5, 284]]) tensor([[285]])\n",
            "tensor([[ 42, 137,   2, 226,  12,   3, 227, 228]]) tensor([[155]])\n",
            "tensor([[  1,   2,   3, 146, 147,  19, 148]]) tensor([[149]])\n",
            "tensor([[  1,   2,   3, 212,   5,  14, 213, 214]]) tensor([[215]])\n",
            "tensor([[  1,   2,   3, 221,   5, 222, 223, 224]]) tensor([[225]])\n",
            "tensor([[78, 79, 80, 81, 82, 83, 84]]) tensor([[85]])\n",
            "tensor([[  1,   2,   3,   4,   5, 236, 237]]) tensor([[238]])\n",
            "tensor([[ 1,  2,  3,  4,  5, 53]]) tensor([[54]])\n",
            "tensor([[  1,   2,   3,   4,   5, 109]]) tensor([[317]])\n",
            "tensor([[ 42, 137,   2,  62,  39,   3, 322, 323]]) tensor([[6]])\n",
            "tensor([[ 10,  75, 208]]) tensor([[209]])\n",
            "tensor([[10, 96,  3, 97]]) tensor([[98]])\n",
            "tensor([[ 42,   2,   3, 210, 137, 168, 211, 169]]) tensor([[113]])\n",
            "tensor([[  1,   2,   3,   4,   5, 279]]) tensor([[280]])\n",
            "tensor([[ 42, 107,   2, 108,  19, 109]]) tensor([[110]])\n",
            "tensor([[ 42,   2,   3, 274, 211, 275]]) tensor([[276]])\n",
            "tensor([[ 10,  11, 189, 158, 190]]) tensor([[191]])\n",
            "tensor([[ 78,  79, 150, 151,  14, 152, 153]]) tensor([[154]])\n",
            "torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "FLliQEhbA7DT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleRNN(nn.Module):\n",
        "\n",
        "  def __init__(self,vocab_size):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size,embedding_dim=50)\n",
        "    self.rnn = nn.RNN(50,64,batch_first=True)\n",
        "    self.fc = nn.Linear(64, vocab_size)\n",
        "\n",
        "  def forward(self,question):\n",
        "    embedded_question = self.embedding(question)\n",
        "    hidden,final = self.rnn(embedded_question)\n",
        "    output = self.fc(final.squeeze(0))\n",
        "\n",
        "    return output\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yCSKA3kJA6_p"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "epochs = 20"
      ],
      "metadata": {
        "id": "8GvV0Q13T9XL"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleRNN(len(vocab))"
      ],
      "metadata": {
        "id": "adhg5gByUKAH"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)"
      ],
      "metadata": {
        "id": "BVIiWQUVUJ7-"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  total_loss = 0\n",
        "\n",
        "  for question,answer in dataloader:\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward pass\n",
        "    output = model(question)\n",
        "\n",
        "    # loss\n",
        "    loss = criterion(output,answer[0])\n",
        "\n",
        "    # gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # update\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "  print(f\"Epoch : {epoch+1} Loss: {total_loss:4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOEAPmRuUJ4v",
        "outputId": "59f4047d-08f2-413b-c3ff-173c543c3bf4"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1 Loss: 527.021381\n",
            "Epoch : 2 Loss: 455.630792\n",
            "Epoch : 3 Loss: 375.358722\n",
            "Epoch : 4 Loss: 313.652239\n",
            "Epoch : 5 Loss: 261.495797\n",
            "Epoch : 6 Loss: 211.871649\n",
            "Epoch : 7 Loss: 168.846631\n",
            "Epoch : 8 Loss: 131.131964\n",
            "Epoch : 9 Loss: 101.332696\n",
            "Epoch : 10 Loss: 77.565926\n",
            "Epoch : 11 Loss: 59.935839\n",
            "Epoch : 12 Loss: 46.751218\n",
            "Epoch : 13 Loss: 37.331668\n",
            "Epoch : 14 Loss: 30.348253\n",
            "Epoch : 15 Loss: 24.935162\n",
            "Epoch : 16 Loss: 21.037449\n",
            "Epoch : 17 Loss: 17.801924\n",
            "Epoch : 18 Loss: 15.275354\n",
            "Epoch : 19 Loss: 13.078550\n",
            "Epoch : 20 Loss: 11.339377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model,question,threshold=0.5):\n",
        "\n",
        "  # convert question into numerical indices\n",
        "  numerical_question = text_to_indices(question,vocab)\n",
        "\n",
        "  # convert numerical indices into tensor\n",
        "  tensor_question = torch.tensor(numerical_question).unsqueeze(0) # to make it (batchsize,dim)\n",
        "\n",
        "  # send to model\n",
        "  output = model(tensor_question)\n",
        "\n",
        "  # convert logit into probabilitities\n",
        "  probs = torch.nn.functional.softmax(output,dim=1)\n",
        "\n",
        "  # find index of max prob\n",
        "  value,index = torch.max(probs,dim=1)\n",
        "\n",
        "  if value < threshold:\n",
        "    print(\"I don't know.\")\n",
        "  else:\n",
        "    print(list(vocab.keys())[index])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4e9fp6u6U6c7"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model,\"what is the capital city of Germany?\")\n"
      ],
      "metadata": {
        "id": "JrglvftaU6ZS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cab5070b-e424-44e8-9444-26737f46c25b"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "berlin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## for underneath understanding\n"
      ],
      "metadata": {
        "id": "aVExJQqhT3_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0][0]"
      ],
      "metadata": {
        "id": "BhmixJJfA8P0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9304e884-04ec-4572-e1f3-2a2084310977"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3, 4, 5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0][0].dtype"
      ],
      "metadata": {
        "id": "nPhjSXRkaPUD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "950264fc-2a16-49b4-92d2-b4bee8dfb703"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.int64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x= nn.Embedding(324,embedding_dim=50)"
      ],
      "metadata": {
        "id": "fKhQLFB2A8G6"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x(dataset[0][0])"
      ],
      "metadata": {
        "id": "s79pfKZFLIAP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "926f026d-5997-4ca2-a927-9c4b1653b4a7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.0227e+00,  5.8167e-01, -1.5518e-01,  1.0700e+00,  1.5804e+00,\n",
              "          1.1146e+00, -1.3937e+00,  1.2640e+00,  1.8745e+00, -3.2424e-01,\n",
              "         -7.4317e-01, -1.5174e+00,  1.2204e+00,  1.3354e+00,  7.0115e-02,\n",
              "          5.3638e-01,  1.1693e+00,  1.7551e+00, -2.7504e-01, -7.6048e-01,\n",
              "         -5.8774e-01,  1.4547e+00,  5.2815e-01, -5.7867e-01,  9.7347e-02,\n",
              "          1.3665e-01,  6.7627e-01, -1.0797e+00,  1.9258e+00,  1.7303e-01,\n",
              "         -9.9373e-02,  6.2178e-01, -3.1118e-01,  7.1450e-02, -2.6328e-01,\n",
              "         -4.0624e-01, -6.0257e-01,  2.3777e+00,  8.4220e-01,  6.8520e-03,\n",
              "         -5.2696e-01, -3.7836e-01,  4.5372e-01, -1.7085e-01,  4.3422e-01,\n",
              "          7.1812e-01, -7.5967e-01, -1.8148e-01,  8.0685e-01, -7.5485e-01],\n",
              "        [-1.6511e+00,  6.9044e-01, -1.3407e+00,  1.5776e+00,  5.6589e-01,\n",
              "          3.5308e-01, -6.4965e-02,  6.7706e-01, -1.9979e-01,  1.2708e-01,\n",
              "         -1.2504e+00,  1.1434e+00,  2.1973e+00,  8.6476e-01, -5.8159e-01,\n",
              "         -4.8683e-01,  9.3527e-01,  1.8208e-01, -6.1994e-01, -8.0623e-01,\n",
              "         -1.2828e+00, -1.1554e+00, -2.6903e-01,  2.2267e-01,  1.0210e+00,\n",
              "          9.9702e-01, -2.3039e-01,  1.1239e-01, -2.5343e-04, -9.9010e-01,\n",
              "          1.0588e+00,  4.2742e-01,  1.3904e+00,  5.3429e-01,  8.6642e-01,\n",
              "         -2.8897e-02,  7.8756e-01,  1.0769e+00, -8.3344e-01,  1.3088e-01,\n",
              "         -6.5944e-01, -2.0346e+00,  8.7088e-01, -3.8485e-01,  5.1845e-01,\n",
              "          9.9031e-01,  6.2332e-01, -2.0037e+00, -2.5121e+00, -5.1289e-01],\n",
              "        [ 5.6793e-01, -6.6215e-01, -2.3636e-01,  1.7317e-01,  8.6534e-03,\n",
              "         -1.5193e+00, -6.7735e-02,  1.8645e+00, -1.8024e+00,  2.1320e-01,\n",
              "         -6.0964e-01,  2.7674e-01, -1.1014e+00, -7.1416e-01,  1.0416e+00,\n",
              "         -1.7798e+00, -1.7329e+00, -7.6263e-01,  9.4909e-01, -3.2700e-02,\n",
              "          1.4064e+00,  3.2194e-01,  8.0101e-01, -7.9932e-01, -4.5946e-01,\n",
              "         -2.2100e-02, -1.7286e-01, -2.5639e+00, -1.2913e+00, -1.1952e+00,\n",
              "          1.8058e+00,  2.7713e-01, -2.0061e+00,  2.4442e-03, -4.8211e-01,\n",
              "          8.9275e-01, -1.8735e+00, -8.6784e-01, -6.3699e-01, -6.5472e-01,\n",
              "          1.1280e-01,  1.6408e-01, -6.9985e-01, -2.7325e-01, -3.7138e-01,\n",
              "         -1.2746e-01, -7.5620e-01, -8.9472e-01, -9.9851e-01,  8.7811e-01],\n",
              "        [ 3.0749e-02,  3.1467e-02,  3.7815e-02,  8.3170e-02,  2.8407e-01,\n",
              "         -7.2885e-02,  1.4011e+00, -4.5058e-01, -2.5035e-01,  6.2431e-01,\n",
              "         -3.9853e-01,  7.1985e-01,  4.3136e-01,  1.0051e+00, -1.1128e+00,\n",
              "          2.4046e+00,  1.7820e+00,  5.9244e-01,  4.6441e-01,  9.8526e-01,\n",
              "         -7.2053e-01, -5.8060e-02, -1.7656e+00,  9.2243e-01, -9.3409e-01,\n",
              "         -3.5886e-01, -8.2786e-01, -6.4508e-01,  2.9344e-01, -1.3081e+00,\n",
              "         -4.0012e-01, -8.1518e-01, -3.1616e-01, -1.1526e-01,  5.4303e-01,\n",
              "          6.2403e-01,  5.8519e-02, -5.2865e-01,  1.2922e-01,  1.6363e+00,\n",
              "         -7.2871e-01,  2.5631e+00,  8.8513e-02, -9.4153e-01,  3.3273e-01,\n",
              "          1.0799e+00, -1.3334e+00, -4.0240e-02, -4.1462e-01, -1.0194e+00],\n",
              "        [ 7.1294e-01,  1.2227e+00,  1.4699e-01,  1.8480e-01,  1.5657e+00,\n",
              "          2.0362e+00,  1.5711e+00, -1.0273e+00,  1.6533e+00,  1.9951e+00,\n",
              "         -1.2852e+00, -5.5970e-01,  1.3159e+00,  4.0857e-01,  1.0390e+00,\n",
              "         -1.1256e+00,  7.5773e-02,  1.2131e+00,  8.6342e-01,  6.7355e-01,\n",
              "         -2.4404e+00,  8.1860e-01, -1.8391e+00, -2.0243e-01,  1.0357e+00,\n",
              "         -1.8130e-01,  9.7925e-01, -5.8875e-01,  9.2794e-01, -1.0637e+00,\n",
              "          4.2634e-01, -8.3010e-01, -8.2154e-01, -5.7570e-01,  8.2369e-01,\n",
              "          7.2798e-01, -2.2391e-01,  1.4143e-01, -1.5239e+00, -1.3320e-01,\n",
              "         -9.0536e-02,  4.8519e-02, -1.3716e+00,  7.0374e-01, -7.4915e-01,\n",
              "         -5.0588e-01,  6.8439e-01,  5.6388e-01, -1.1240e+00, -6.7000e-01],\n",
              "        [-9.0685e-01,  2.9415e-01,  5.4579e-01, -1.2272e+00,  7.3285e-01,\n",
              "          5.0524e-01, -4.3166e-01, -9.4829e-01, -2.5794e-01,  1.5853e+00,\n",
              "          9.3144e-01,  1.3552e+00,  1.9344e+00,  2.1274e+00,  3.6463e-01,\n",
              "         -1.4134e+00, -1.7843e-01,  1.1595e+00, -5.7241e-01,  7.2155e-01,\n",
              "          1.6812e-01,  1.0378e+00,  4.0487e-02, -1.3936e+00,  2.9502e-01,\n",
              "         -8.6829e-01,  4.1290e-01, -5.1618e-01,  3.8614e-02, -3.8689e-01,\n",
              "         -1.6120e+00,  5.2526e-01, -1.3708e+00,  7.2352e-01,  1.9545e+00,\n",
              "          1.0833e+00,  5.8513e-01, -1.0819e+00,  2.0699e+00,  4.5679e-01,\n",
              "         -6.0487e-01,  2.3489e-01,  1.1368e+00, -1.1565e+00,  3.9610e-02,\n",
              "         -1.5083e+00, -4.1142e-01,  9.5206e-01,  4.1656e-01, -5.8428e-01]],\n",
              "       grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x(dataset[0][0]).dtype"
      ],
      "metadata": {
        "id": "RhreiVQVeAeH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6ce9ebb-be72-4bdb-cbfc-4655208dfa6a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x(dataset[0][0]).shape"
      ],
      "metadata": {
        "id": "HKvLD64JLH8-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34e5eef7-edac-4e68-b669-009f0ba0319b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 50])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = x(dataset[0][0])"
      ],
      "metadata": {
        "id": "V_25eieRLH5l"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = nn.RNN(50,64)"
      ],
      "metadata": {
        "id": "Knfnqgk2L7tE"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y(a)"
      ],
      "metadata": {
        "id": "xY6QlhDTMAsD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa238e31-ad2f-443f-b682-97536148a707"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-2.9986e-01,  2.8012e-01,  5.4653e-02,  4.6459e-01,  3.4977e-01,\n",
              "           3.2933e-02, -3.9721e-01, -3.7181e-02, -2.7648e-01, -7.4611e-01,\n",
              "          -6.2870e-01,  6.9327e-01, -2.4400e-03, -2.9774e-01, -8.9080e-02,\n",
              "           1.4464e-01, -8.2299e-01, -4.7901e-01,  2.6214e-01, -2.0204e-01,\n",
              "          -3.2281e-02, -2.7066e-01,  1.4277e-01, -5.1513e-01,  5.3059e-01,\n",
              "           6.1029e-01,  1.8763e-01,  9.2579e-02,  4.9404e-01, -3.9382e-01,\n",
              "           7.4287e-01,  4.1594e-01,  4.8616e-01,  1.9959e-01, -1.3971e-03,\n",
              "          -4.1455e-01, -2.4286e-01, -1.6374e-01, -3.8591e-01, -5.5040e-01,\n",
              "           7.0835e-01,  6.4380e-01, -3.8123e-01, -1.1455e-02, -3.2625e-01,\n",
              "           5.8380e-01, -2.0497e-01,  2.5512e-01,  5.3148e-01, -8.1370e-02,\n",
              "           4.6605e-01, -5.9193e-01, -4.5505e-01,  7.0953e-01, -8.0320e-01,\n",
              "           8.3807e-01, -6.7895e-01, -1.7854e-02,  6.6715e-01,  2.4510e-01,\n",
              "          -5.7820e-02,  6.4231e-01, -4.1449e-02,  4.7408e-01],\n",
              "         [-1.7760e-01, -7.3312e-01, -6.6937e-01, -3.2928e-01,  4.6329e-01,\n",
              "          -6.9391e-02, -6.2452e-01,  3.3432e-01,  3.4806e-01,  2.0222e-01,\n",
              "          -2.9385e-01,  4.4605e-02,  7.3590e-01,  4.7391e-01,  8.1258e-01,\n",
              "           9.4706e-01, -4.0309e-01, -7.0497e-01, -3.9779e-01, -4.8848e-01,\n",
              "           7.4941e-02,  1.3277e-01,  7.3085e-01, -1.0868e-01, -1.0030e-01,\n",
              "           7.2792e-01,  2.9779e-01,  1.6553e-01,  7.1937e-01, -3.6582e-01,\n",
              "           8.6867e-02,  1.1111e-01,  8.9564e-01, -6.5607e-01,  6.1237e-02,\n",
              "           3.6899e-01, -3.0040e-01, -4.2009e-01, -6.9497e-01, -3.0340e-01,\n",
              "           7.1956e-01,  4.9668e-01,  8.3132e-01, -8.0098e-01, -4.2566e-01,\n",
              "           6.3954e-02, -9.6288e-02,  3.7764e-01, -7.4406e-01,  3.9713e-01,\n",
              "           7.8152e-01, -3.5496e-01, -1.6209e-01,  6.2563e-01, -8.2685e-01,\n",
              "           7.7536e-02, -3.7152e-01,  6.7148e-01, -2.9227e-01, -3.2704e-01,\n",
              "           5.9775e-02,  7.7232e-01, -1.5587e-01,  3.9894e-01],\n",
              "         [ 6.4375e-01,  2.4543e-01,  2.4129e-01, -1.3248e-01, -5.6975e-02,\n",
              "          -5.9370e-01, -4.6969e-01,  9.0941e-02,  5.1894e-01, -1.5658e-02,\n",
              "           5.4637e-04, -8.8506e-01,  3.2265e-01,  4.1445e-01,  8.3033e-02,\n",
              "           4.1353e-01,  1.7384e-01,  5.8969e-01,  2.2983e-01,  3.8565e-01,\n",
              "          -2.2475e-01, -3.7965e-01, -4.7805e-01, -5.3511e-01, -2.0945e-01,\n",
              "          -8.7846e-01, -3.0068e-01,  4.2824e-01,  5.9626e-02,  4.8119e-01,\n",
              "          -6.7514e-01, -6.8603e-02, -8.7403e-01, -7.7398e-01, -4.0447e-03,\n",
              "           9.2931e-01,  2.0953e-01,  1.6298e-01, -4.6330e-02,  2.7748e-01,\n",
              "           1.1699e-01,  9.6897e-02, -7.5021e-03,  5.4108e-01,  5.2228e-01,\n",
              "           2.2779e-01, -3.0619e-01,  4.3920e-01, -5.4252e-01,  5.6536e-01,\n",
              "           7.2165e-02,  6.2170e-01,  4.4940e-01, -7.6626e-01,  4.2761e-01,\n",
              "          -3.3627e-01, -5.4726e-01,  5.6390e-01,  2.0825e-01,  2.2484e-01,\n",
              "          -1.9288e-01, -1.7339e-01,  4.6624e-01,  2.9528e-01],\n",
              "         [-4.1390e-01,  3.6199e-01,  5.9958e-01,  6.7522e-01,  6.9583e-01,\n",
              "           3.9260e-01, -5.1241e-01, -1.1161e-01, -1.3103e-01, -1.3541e-01,\n",
              "           1.2484e-01,  4.7306e-01,  2.2900e-01, -5.3052e-01,  3.4779e-01,\n",
              "           2.6344e-01,  1.6700e-01, -7.1075e-01, -4.5895e-01, -1.5981e-01,\n",
              "          -1.3866e-01, -4.9487e-01, -6.1438e-01, -3.7383e-01, -2.8654e-01,\n",
              "           2.4224e-01,  8.0273e-01, -2.6429e-01,  3.8189e-01, -2.3796e-01,\n",
              "           6.3473e-01,  5.0641e-01,  2.7355e-02, -1.2028e-01,  1.4940e-01,\n",
              "          -6.1190e-02, -6.2326e-01,  5.2522e-01, -3.1394e-01, -3.3094e-01,\n",
              "           2.9171e-01,  6.1539e-01,  2.4285e-02, -3.4392e-01, -3.5190e-01,\n",
              "          -2.8453e-03,  2.6352e-01, -8.4654e-01,  5.3137e-01,  3.2459e-02,\n",
              "           2.9749e-01,  2.9832e-01, -6.8632e-01, -3.3048e-01, -5.6148e-01,\n",
              "          -3.0630e-01,  2.7622e-01,  3.8418e-01, -8.1030e-02,  3.5809e-01,\n",
              "          -1.9534e-02,  1.9954e-01, -6.9014e-01,  7.4345e-01],\n",
              "         [ 4.6368e-01,  4.7366e-01,  1.2540e-02, -5.8186e-01,  5.7174e-01,\n",
              "           5.9331e-01,  9.6538e-02,  2.0089e-01, -5.6057e-02,  9.6427e-01,\n",
              "          -1.7326e-01, -2.8789e-01,  1.9207e-01,  5.5327e-01,  7.2291e-02,\n",
              "           8.9100e-01, -4.0516e-01, -7.0037e-01, -4.2108e-01, -4.4054e-01,\n",
              "          -3.2470e-01, -2.2307e-01, -9.1630e-01, -7.9910e-01,  2.4379e-01,\n",
              "           2.1712e-02,  8.0397e-01, -9.6507e-02,  2.5139e-01, -7.1691e-01,\n",
              "           8.8633e-01, -8.5896e-01,  1.1810e-01, -3.4826e-02,  4.9852e-01,\n",
              "           3.7884e-01, -3.5815e-01, -3.7883e-01, -7.2025e-01, -2.4459e-01,\n",
              "          -2.6130e-01,  1.4754e-01, -5.0786e-01, -3.1792e-01, -5.5551e-01,\n",
              "           3.8275e-01, -2.9010e-01,  6.0198e-01,  1.0630e-01,  3.5705e-01,\n",
              "           4.7621e-01,  5.4166e-01,  6.4483e-02,  2.1148e-01, -1.2223e-01,\n",
              "           2.6911e-01,  3.5580e-01,  2.6547e-01, -8.4562e-02,  5.5763e-01,\n",
              "          -2.2716e-01,  6.8533e-01, -3.0955e-01, -3.1153e-01],\n",
              "         [-5.7118e-01, -5.9637e-01,  1.0018e-01,  5.8532e-01, -3.4892e-01,\n",
              "           6.8106e-01, -2.5671e-01, -1.2407e-01, -3.5689e-01, -5.4594e-01,\n",
              "          -5.4281e-01, -6.2734e-02, -5.3272e-01,  5.3914e-01,  3.9702e-01,\n",
              "           7.3910e-01, -1.6772e-01,  5.4536e-01,  7.6597e-01, -6.3351e-01,\n",
              "          -4.0099e-01, -1.8946e-01,  5.8453e-01, -7.4954e-01,  4.7279e-01,\n",
              "          -3.9273e-02, -5.4319e-01,  9.7727e-02,  8.1098e-01, -3.3102e-01,\n",
              "           3.5064e-01,  4.5805e-01,  3.9660e-01, -7.0570e-01, -2.9601e-01,\n",
              "           3.7235e-01, -1.6714e-01, -2.2365e-01,  7.0866e-01, -7.4056e-01,\n",
              "          -6.8254e-01,  2.2739e-03, -7.2243e-01, -5.8302e-02,  5.6793e-02,\n",
              "           4.8133e-01,  1.9643e-01, -7.5940e-01,  1.4274e-01,  6.9029e-01,\n",
              "           2.1365e-02,  2.9435e-01,  4.3784e-01,  6.2540e-01, -2.7213e-01,\n",
              "           2.6400e-01,  4.3586e-01, -6.8624e-02,  1.5981e-01, -5.8415e-01,\n",
              "           1.6407e-01,  3.7364e-01,  3.7485e-01,  2.9806e-01]],\n",
              "        grad_fn=<SqueezeBackward1>),\n",
              " tensor([[-0.5712, -0.5964,  0.1002,  0.5853, -0.3489,  0.6811, -0.2567, -0.1241,\n",
              "          -0.3569, -0.5459, -0.5428, -0.0627, -0.5327,  0.5391,  0.3970,  0.7391,\n",
              "          -0.1677,  0.5454,  0.7660, -0.6335, -0.4010, -0.1895,  0.5845, -0.7495,\n",
              "           0.4728, -0.0393, -0.5432,  0.0977,  0.8110, -0.3310,  0.3506,  0.4580,\n",
              "           0.3966, -0.7057, -0.2960,  0.3724, -0.1671, -0.2237,  0.7087, -0.7406,\n",
              "          -0.6825,  0.0023, -0.7224, -0.0583,  0.0568,  0.4813,  0.1964, -0.7594,\n",
              "           0.1427,  0.6903,  0.0214,  0.2943,  0.4378,  0.6254, -0.2721,  0.2640,\n",
              "           0.4359, -0.0686,  0.1598, -0.5842,  0.1641,  0.3736,  0.3749,  0.2981]],\n",
              "        grad_fn=<SqueezeBackward1>))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_layer = y(a)[0].shape\n",
        "hidden_layer"
      ],
      "metadata": {
        "id": "XYaf077eMBfz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f550ab1a-dc32-4a2f-f754-9f6efd8c426b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y(a)[0].dtype"
      ],
      "metadata": {
        "id": "z3u1PgAxfKkI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8681d0aa-2021-4b7a-cfaf-4845c676bafb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "output_layer = y(a)[1].shape\n",
        "output_layer"
      ],
      "metadata": {
        "id": "Cn6Su2PeMU5D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d86b6e86-9393-42b6-868f-b41e07b5b4d7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# final output\n",
        "b= y(a)[1]"
      ],
      "metadata": {
        "id": "tlBsErFFNS5C"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y(a)[1].dtype"
      ],
      "metadata": {
        "id": "gn6v51r9fQE-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b7743fc-9daa-4e1a-bf7d-9a783705480b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = nn.Linear(64, 324)"
      ],
      "metadata": {
        "id": "jzmzZHaxNS1T"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z(b)"
      ],
      "metadata": {
        "id": "VLl8k57tP2KR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e44827e7-b905-4a32-ded6-1ccdd57c3445"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0785,  0.2492,  0.3124, -0.0185, -0.2593,  0.4270,  0.0530, -0.1348,\n",
              "         -0.1274,  0.0412,  0.0343,  0.0168, -0.1478, -0.0023,  0.2606, -0.5019,\n",
              "         -0.0326, -0.0477,  0.0409, -0.3552,  0.3978, -0.2420,  0.0414,  0.2874,\n",
              "          0.4015, -0.1583,  0.0491,  0.5096,  0.0619,  0.0607, -0.0291, -0.0541,\n",
              "         -0.1620,  0.3719,  0.0065, -0.1140,  0.1641,  0.1338,  0.4676,  0.4500,\n",
              "          0.6068,  0.1663,  0.0343, -0.2084, -0.1477,  0.0315, -0.2391, -0.2228,\n",
              "         -0.0645,  0.3941, -0.1124,  0.0438,  0.3537,  0.3052, -0.0517,  0.0258,\n",
              "         -0.0252, -0.0081, -0.1417,  0.2815,  0.3740, -0.1534, -0.0287, -0.2183,\n",
              "         -0.2070, -0.7825,  0.1407,  0.2414,  0.0582, -0.2169,  0.5208,  0.4127,\n",
              "          0.0412, -0.5791, -0.0385,  0.4260, -0.2290,  0.0545,  0.0388,  0.0045,\n",
              "          0.1172, -0.0688,  0.2020,  0.5101, -0.0015,  0.0686, -0.0532, -0.3311,\n",
              "          0.0840,  0.1906, -0.1158, -0.0408,  0.3688,  0.0138, -0.3350,  0.1260,\n",
              "          0.1210, -0.1397,  0.3583,  0.1173,  0.2168, -0.1159,  0.2818,  0.0311,\n",
              "          0.3044,  0.2215, -0.2787,  0.0769,  0.0945, -0.6134,  0.0984,  0.0384,\n",
              "          0.2280, -0.2307, -0.1780,  0.6339, -0.4774, -0.0730,  0.0572, -0.0459,\n",
              "          0.0871, -0.3311,  0.0602,  0.0320, -0.2159,  0.1496,  0.1643,  0.5859,\n",
              "         -0.2406, -0.0959, -0.1325, -0.1563, -0.3072, -0.1726, -0.5044, -0.0113,\n",
              "         -0.0925, -0.2303,  0.1215,  0.1020,  0.2425, -0.5418,  0.9235, -0.1691,\n",
              "          0.1478, -0.2462, -0.2416,  0.1742, -0.4835, -0.0843,  0.5627, -0.1319,\n",
              "         -0.2879,  0.7446,  0.3946,  0.0821, -0.1243,  0.3791, -0.4221, -0.1354,\n",
              "         -0.2017,  0.2830,  0.4496, -0.1212, -0.0341,  0.2820,  0.0142,  0.6436,\n",
              "         -0.3310, -0.2424,  0.0131, -0.1203, -0.1174,  0.7252,  0.0276, -0.0383,\n",
              "          0.0022, -0.4459, -0.6014,  0.0381,  0.0885,  0.2046,  0.3455,  0.4088,\n",
              "          0.2244,  0.0551,  0.0905,  0.4688, -0.0483,  0.3080,  0.2969,  0.3949,\n",
              "          0.0877, -0.3520,  0.0048, -0.6174,  0.4933, -0.5595,  0.1058, -0.1148,\n",
              "         -0.0193, -0.1054,  0.0805,  0.0815, -0.2218, -0.6425,  0.5141,  0.2470,\n",
              "          0.1514,  0.4986,  0.3545, -0.9761,  0.1008,  0.1934,  0.0116, -0.0932,\n",
              "         -0.4604, -0.1137,  0.4057,  0.0173, -0.0173, -0.0559,  0.0224,  0.1826,\n",
              "          0.3215, -0.0826,  0.1751, -0.0975,  0.1994,  0.0846,  0.1017, -0.1208,\n",
              "          0.1508, -0.1172, -0.4649, -0.3134, -0.4002, -0.1214, -0.0603,  0.0881,\n",
              "          0.9196,  0.1338,  0.3043, -0.2827, -0.0614, -0.4058, -0.2616,  0.4282,\n",
              "          0.1522,  0.0387, -0.0223,  0.6386, -0.1267,  0.2934,  0.2725, -0.1219,\n",
              "          0.6311,  0.5078,  0.2589, -0.6278,  0.0468, -0.3821,  0.0658,  0.0606,\n",
              "         -0.1740,  0.0499, -0.0246,  0.2191, -0.3505,  0.3181,  0.2351,  0.0788,\n",
              "         -0.4501,  0.0165, -0.2972,  0.0050,  0.2264,  0.1399,  0.3089,  0.1229,\n",
              "          0.0348,  0.2110, -0.2018,  0.3609, -0.2085,  0.0751,  0.1971,  0.9130,\n",
              "         -0.3851, -0.3788,  0.1031,  0.4100, -0.2292, -0.1317,  0.1328,  0.0246,\n",
              "         -0.1945,  0.0783,  0.0973,  0.2194,  0.0452, -0.4923, -0.6101,  0.1589,\n",
              "          0.2958,  0.3461,  0.0526,  0.2054,  0.1249,  0.1209,  0.0593,  0.2059,\n",
              "         -0.2474,  0.1207, -0.0916, -0.0147, -0.0539,  0.0874, -0.0062, -0.0466,\n",
              "         -0.3051,  0.0429, -0.4659,  0.1837]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z(b).shape"
      ],
      "metadata": {
        "id": "RrlP9yivQAJf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "738f2d4b-e4d6-41d1-f7e6-6c8da709c7d4"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 324])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z(b).dtype"
      ],
      "metadata": {
        "id": "nl476aVpQAFS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0e1b7e2-6c36-40b4-dcba-dd7abf2106c1"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RC4tj4s6fVim"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}